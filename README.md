
# 🎭 Gesture & Emotion Recognition AI  

## 🚀 Overview  
This project is a **gesture and facial-expression-based AI system** that detects hand gestures and facial expressions using **MediaPipe** and a **deep learning model**. The model is trained to recognize gestures and emotions and apply them in **real-world applications**, such as:  
- **Real-time emotion-based music recommendations** 🎶  
- **Gesture-based interaction** 🖐️  

## ✨ Features  
✅ **Real-time gesture and facial recognition** using **MediaPipe**  
✅ **Trainable deep learning model** with **TensorFlow/Keras**  
✅ **Interactive AI applications** (e.g., emotion-based song recommendations)  
✅ **Webcam-based real-time predictions**  
✅ **Easy-to-use Streamlit UI**  

---

## 🛠️ Technologies Used  
- 🎥 **MediaPipe** - Real-time landmark detection  
- 🤖 **TensorFlow/Keras** - Model training and inference  
- 🎮 **OpenCV** - Video processing  
- 🎶 **Streamlit + WebRTC** - Web-based interface for emotion detection  
- 📝 **NumPy** - Data handling and storage  

---

## 📂 Project Structure  

| File | Description |
|------|------------|
| `data_collection.py` | Collects gesture and facial expression data using **MediaPipe** |
| `data_training.py` | Trains a **deep learning model** on collected data |
| `inference.py` | Runs real-time predictions using the trained model |
| `music.py` | Detects emotions and recommends songs based on mood |

---

## 📥 Installation  

### 🔹 Prerequisites  
Ensure you have **Python 3.8+** installed. Install dependencies using:  

```bash
pip install -r requirements.txt
