
# ğŸ­ Gesture & Emotion Recognition AI  

## ğŸš€ Overview  
This project is a **gesture and facial-expression-based AI system** that detects hand gestures and facial expressions using **MediaPipe** and a **deep learning model**. The model is trained to recognize gestures and emotions and apply them in **real-world applications**, such as:  
- **Real-time emotion-based music recommendations** ğŸ¶  
- **Gesture-based interaction** ğŸ–ï¸  

## âœ¨ Features  
âœ… **Real-time gesture and facial recognition** using **MediaPipe**  
âœ… **Trainable deep learning model** with **TensorFlow/Keras**  
âœ… **Interactive AI applications** (e.g., emotion-based song recommendations)  
âœ… **Webcam-based real-time predictions**  
âœ… **Easy-to-use Streamlit UI**  

---

## ğŸ› ï¸ Technologies Used  
- ğŸ¥ **MediaPipe** - Real-time landmark detection  
- ğŸ¤– **TensorFlow/Keras** - Model training and inference  
- ğŸ® **OpenCV** - Video processing  
- ğŸ¶ **Streamlit + WebRTC** - Web-based interface for emotion detection  
- ğŸ“ **NumPy** - Data handling and storage  

---

## ğŸ“‚ Project Structure  

| File | Description |
|------|------------|
| `data_collection.py` | Collects gesture and facial expression data using **MediaPipe** |
| `data_training.py` | Trains a **deep learning model** on collected data |
| `inference.py` | Runs real-time predictions using the trained model |
| `music.py` | Detects emotions and recommends songs based on mood |

---

## ğŸ“¥ Installation  

### ğŸ”¹ Prerequisites  
Ensure you have **Python 3.8+** installed. Install dependencies using:  

```bash
pip install -r requirements.txt
